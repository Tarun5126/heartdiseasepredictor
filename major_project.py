# -*- coding: utf-8 -*-
"""Major Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yeuBpuPjEpraULAvqlBXwhsbojPU9670
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Importing libraries**"""

# Commented out IPython magic to ensure Python compatibility.
#Importing all the necessary libraries

import pandas as pd               #offers various data structures & operations on them 
import numpy as np                #useful for working with arrays
import matplotlib.pyplot as plt   #for data visualization
import seaborn as sb              #this is also for data visualization but high-level 

# %matplotlib inline

import os
print(os.listdir())

import warnings
warnings.filterwarnings('ignore')

"""**Importing Dataset**"""

dataset = pd.read_csv('/content/drive/MyDrive/heart_dataset1.csv')      #fetches the dataset from drive

"""**Understanding Data**"""

dataset.head()                   #prints the first 5 values

"""**Removing NULL values**

**Description**
"""

dataset.shape                  #After removing the null values records we are left with 297 rows

dataset.describe()

dataset.info()

"""**Visualization of Attributes with X axis as values & Y axis as Frequency**"""

print(plt.hist(dataset.AGE,edgecolor="Black"))

print(plt.hist(dataset.THALACH,edgecolor="Black"))

print(plt.hist(dataset.OLDPEAK,edgecolor="Black"))

print(plt.hist(dataset.TRESTBPS,edgecolor="Black"))

print(plt.hist(dataset.CHOL,edgecolor="Black"))

dataset.hist(figsize=(16,16),edgecolor="Black")
plt.show()

"""**Histograms and correlation scatterplots**"""

from mlxtend.plotting import scatterplotmatrix
cols = ["AGE","THALACH","OLDPEAK","TRESTBPS","CHOL","CP"]
scatterplotmatrix(dataset[cols].values,figsize=(25,25),names = cols, alpha=0.6,edgecolor="Black")
plt.tight_layout()
plt.show()

"""**HEAT MAP FOR CORRELATION FEATURES**"""

dataset.corr()               #r = (Covariance of X & Y)/(Std(X)*Std(Y))

plt.figure(figsize=(12,10))
cor = dataset.corr()
sb.heatmap(cor, annot = True ,cmap=plt.cm.Reds)               #if annot is True then correlation coefficients will printed in each cell
plt.show()

"""**Feature Selection Using Least-Absolute-Shrinkage-Selection-Operator(LASSO)**"""

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, GridSearchCV, LeaveOneOut
from sklearn.linear_model import Lasso

X = dataset.iloc[:,:-1]
y = dataset.iloc[:,-1]

features = dataset.drop("NUM",axis=1).columns
features

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=0)

pipeline = Pipeline([
                     ('scaler',StandardScaler()),
                     ('model',Lasso())
                    ])

search = GridSearchCV(pipeline,
                      {'model__alpha':np.arange(0.1,10,0.1)},
                      cv = 10, scoring="neg_mean_squared_error",verbose=3
                      )

search.fit(X_train,y_train)

print(search.best_params_)
print("-"*100)
coefficients = search.best_estimator_.named_steps['model'].coef_
importance = np.abs(coefficients)
print(importance)

print(np.array(features)[importance > 0])
print("-"*100)
print(np.array(features)[importance==0])

#Another method

"""In 'P' variable we take all the attributes belonging to the dataframe except target attribute "NUM".
In 'q' variable we take the target attribute belonging to the dataframe
"""

P = dataset.drop("NUM",axis=1).values                    
q = dataset["NUM"].values                                 
print(P)
print(q)

"""Taking the names of attributes for further usage in plotting the graph between coefficient and attributes"""

attribute_names = dataset.drop("NUM",axis=1).columns
print(attribute_names)

"""Training Lasso model using different alpha values i.e.,learning rate and choosing the appropriate features that are related to output"""

lasso = Lasso(alpha=0.1)
lasso_coef = lasso.fit(P,q).coef_
plt.plot(range(len(attribute_names)),lasso_coef)
plt.xticks(range(len(attribute_names)),attribute_names,rotation=60)
plt.ylabel("Coefficients")

plt.show()

from tabulate import tabulate

lasso = Lasso(alpha=0.01)
lasso_coef = lasso.fit(P,q).coef_
j=0
attributes = []
coefficients = []
for i in attribute_names:
  attributes.append(i)
  coefficients.append(str(round(lasso_coef[j],4)))
  #print(i+": "+str(round(lasso_coef[j],4)))
  j+=1

data = {
      "Attributes": attributes,
      "Coefficients": coefficients
  }
Score_Table = pd.DataFrame(data)
print(tabulate(Score_Table,headers = 'keys',tablefmt = 'psql'))
#print(Score_Table)

plt.plot(range(len(attribute_names)),lasso_coef)
plt.xticks(range(len(attribute_names)),attribute_names,rotation=60)
plt.ylabel("Coefficients")

plt.show()

"""By seeing the above graphs we can understand that when alpha is 0.1 there is no much difference between the coefficients of features w.r.t the output feature.But, alpha with 0.01 is having considerable difference between the coefficients of features.So, it becomes easy to select the required features from the graph to further use in the classifier models.

**Using attributes that are selected from LASSO**

Considering LASSO with 0.01 learning rate the top 6 attributes are going to be used for further classifiers
"""

LASSO_Attributes = dataset[["SEX","CP","EXANG","SLOPE","CA","THAL","NUM"]]

print(LASSO_Attributes.shape)

print("-"*100)

X = LASSO_Attributes[["SEX","CP","EXANG","SLOPE","CA","THAL"]]         #These are predictor variables 
y = LASSO_Attributes["NUM"]                                            #This is response variable

print(X,y,sep="\n\n")

"""**Logistic Regression**"""

from sklearn.linear_model import LogisticRegressionCV, LogisticRegression           #Importing LogisticRegression class from sklearn.linear_model
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix

model_lrcv = LogisticRegression()
accuracy_lrcv = cross_val_score(model_lrcv,X,y,cv=LeaveOneOut(),scoring="accuracy",n_jobs=-1)

print("Accuracy: ",round(np.mean(accuracy_lrcv)*100,2),"%",sep="")

print("-"*100)

#cv = LeaveOneOut()                                                                  #For LOSO_CV (Leave-one-subject-out-cross-validation)
model_lrcv = LogisticRegressionCV()                                                  #For modeling Logistic Regression
#print(model_lrcv)
accuracy_lrcv = cross_val_score(model_lrcv,X,y,scoring="accuracy",n_jobs=-1,cv=10)

print("Accuracy: ",round(np.mean(accuracy_lrcv)*100,2),"%",sep="")

"""--------------------------------------------------------------------------------------

**Spliting of Dataset**
"""

from sklearn.model_selection import train_test_split

X = LASSO_Attributes[["SEX","CP","EXANG","SLOPE","CA","THAL"]]
y = LASSO_Attributes["NUM"]

X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.20,random_state=0)

print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

"""**Logistic Regression**

**Model Fitting & Prediction**
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, accuracy_score, recall_score, precision_score, matthews_corrcoef

Lo_Re_LASSO = LogisticRegression()
scaler = StandardScaler()
X_LR_train = scaler.fit_transform(X_train)
Lo_Re_LASSO.fit(X_LR_train,Y_train)
X_LR_test = scaler.transform(X_test)
Y_pred_LR_LASSO = Lo_Re_LASSO.predict(X_LR_test)

Y_pred_LR_LASSO.shape

"""**Evaluation Metrics**"""

print(classification_report(Y_test,Y_pred_LR_LASSO))

print(confusion_matrix(Y_test,Y_pred_LR_LASSO))

print(plot_confusion_matrix(Lo_Re_LASSO,X_LR_test,Y_test))

accuracy_LR_LASSO = round(accuracy_score(Y_test,Y_pred_LR_LASSO)*100,4)
#print("Accuracy: ",accuracy_LR_LASSO,end="\n")

sensitivity_LR_LASSO = round(recall_score(Y_test, Y_pred_LR_LASSO, pos_label=1)*100,4)
specificity_LR_LASSO = round(recall_score(Y_test, Y_pred_LR_LASSO, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_LR_LASSO,"\n","Specificity: ",specificity_LR_LASSO,sep="")

precision_positive_LR_LASSO = round(precision_score(Y_test, Y_pred_LR_LASSO, pos_label=1)*100,4)
#print("Precision: ",precision_positive_LR_LASSO)
MCC_LR_LASSO = round(matthews_corrcoef(Y_test, Y_pred_LR_LASSO)*100,4)
#print("MCC: ",MCC_LR_LASSO)

Evaluation_Metrics_LR_LASSO = {
    "Metrics": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Values": [accuracy_LR_LASSO, sensitivity_LR_LASSO, specificity_LR_LASSO, precision_positive_LR_LASSO, MCC_LR_LASSO]
}

print(tabulate(Evaluation_Metrics_LR_LASSO, headers = "keys", tablefmt = "psql"))

"""**K-NN**

**Model Fitting, Prediction & Evaluation Metrcis**
"""

from sklearn.neighbors import KNeighborsClassifier
L = []
for k in [1,3,7]:
  KNN_LASSO = KNeighborsClassifier(n_neighbors=k)
  KNN_LASSO.fit(X_train,Y_train)
  Y_pred_KNN_LASSO=KNN_LASSO.predict(X_test)
  L.append(round(accuracy_score(Y_test,Y_pred_KNN_LASSO)*100,4))
accuracy_KNN_LASSO = max(L)
#print("Accuracy: ",accuracy_KNN_LASSO)

sensitivity_KNN_LASSO = round(recall_score(Y_test, Y_pred_KNN_LASSO, pos_label=1)*100,4)
specificity_KNN_LASSO = round(recall_score(Y_test, Y_pred_KNN_LASSO, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_KNN_LASSO,"\n", "Specificity: ",specificity_KNN_LASSO,sep="")

precision_positive_KNN_LASSO = round(precision_score(Y_test, Y_pred_LR_LASSO, pos_label=1)*100,4)
#print("Precision: ",precision_positive_KNN_LASSO)

MCC_KNN_LASSO = round(matthews_corrcoef(Y_test, Y_pred_LR_LASSO)*100,4)
#print("MCC: ",MCC_KNN_LASSO)

Evaluation_Metrics_LR_KNN = {
    "Metrics": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Values": [accuracy_KNN_LASSO, sensitivity_KNN_LASSO, specificity_KNN_LASSO, precision_positive_KNN_LASSO, MCC_KNN_LASSO]
}

print(tabulate(Evaluation_Metrics_LR_KNN, headers = "keys", tablefmt = "psql"))
print('-'*100)
print(plot_confusion_matrix(KNN_LASSO,X_test,Y_test))

"""**SVM(rbf)**

**Model Fitting, Prediction & Evaluation**
"""

from sklearn import svm

SVM_RBF_LASSO = svm.SVC(kernel='rbf')
SVM_RBF_LASSO.fit(X_train, Y_train)
Y_pred_SVM_RBF_LASSO = SVM_RBF_LASSO.predict(X_test)


accuracy_SVM_RBF_LASSO = round(accuracy_score(Y_pred_SVM_RBF_LASSO,Y_test)*100,4)
#print("Accuracy: ",accuracy_SVM_RBF_LASSO)

sensitivity_SVM_RBF_LASSO = round(recall_score(Y_test, Y_pred_SVM_RBF_LASSO, pos_label=1)*100,4)
specificity_SVM_RBF_LASSO = round(recall_score(Y_test, Y_pred_SVM_RBF_LASSO, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_SVM_RBF_LASSO,"\n", "Specificity: ",specificity_SVM_RBF_LASSO,sep="")

precision_positive_SVM_RBF_LASSO = round(precision_score(Y_test, Y_pred_SVM_RBF_LASSO, pos_label=1)*100,4)
#print("Precision: ",precision_positive_SVM_RBF_LASSO)

MCC_SVM_RBF_LASSO = round(matthews_corrcoef(Y_test, Y_pred_SVM_RBF_LASSO)*100,4)
#print("MCC: ",MCC_SVM_RBF_LASSO)

Evaluation_Metrics_LR_SVM_RBF = {
    "Metrics": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Values": [accuracy_SVM_RBF_LASSO, sensitivity_SVM_RBF_LASSO, specificity_SVM_RBF_LASSO, precision_positive_SVM_RBF_LASSO, MCC_SVM_RBF_LASSO]
}

print(tabulate(Evaluation_Metrics_LR_SVM_RBF, headers = "keys", tablefmt = "psql"))
print("-"*100)
print(plot_confusion_matrix(SVM_RBF_LASSO,X_test,Y_test))

"""**SVM(linear)**

**Model Fitting, Prediction & Evaluation Metrics**
"""

from sklearn import svm

SVM_LI_LASSO = svm.SVC(kernel='linear')
SVM_LI_LASSO.fit(X_train, Y_train)
Y_pred_SVM_LI_LASSO = SVM_LI_LASSO.predict(X_test)

accuracy_SVM_LI_LASSO = round(accuracy_score(Y_pred_SVM_LI_LASSO,Y_test)*100,4)
#print("Accuracy: ",accuracy_SVM_LI_LASSO)

sensitivity_SVM_LI_LASSO = round(recall_score(Y_test, Y_pred_SVM_LI_LASSO, pos_label=1)*100,4)
specificity_SVM_LI_LASSO = round(recall_score(Y_test, Y_pred_SVM_LI_LASSO, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_SVM_LI_LASSO,"\n", "Specificity: ",specificity_SVM_LI_LASSO,sep="")

precision_positive_SVM_LI_LASSO = round(precision_score(Y_test, Y_pred_SVM_LI_LASSO, pos_label=1)*100,4)
#print("Precision: ",precision_positive_SVM_LI_LASSO)

MCC_SVM_LI_LASSO = round(matthews_corrcoef(Y_test, Y_pred_SVM_LI_LASSO)*100,4)
#print("MCC: ",MCC_SVM_LI_LASSO)

Evaluation_Metrics_LR_SVM_LI = {
    "Metrics": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Values": [accuracy_SVM_LI_LASSO, sensitivity_SVM_LI_LASSO, specificity_SVM_LI_LASSO, precision_positive_SVM_LI_LASSO, MCC_SVM_LI_LASSO]
}

print(tabulate(Evaluation_Metrics_LR_SVM_LI, headers = "keys", tablefmt = "psql"))
print('-'*100)
print(plot_confusion_matrix(SVM_LI_LASSO,X_test,Y_test))

"""**Naive Bayes**

**Model Fitting, Prediction & Evaluation Metrics**
"""

from sklearn.naive_bayes import GaussianNB

NB_LASSO = GaussianNB()
NB_LASSO.fit(X_train,Y_train)
Y_pred_NB_LASSO = NB_LASSO.predict(X_test)

accuracy_NB_LASSO = round(accuracy_score(Y_pred_NB_LASSO,Y_test)*100,4)
#print("Accuracy: ",accuracy_NB_LASSO)

sensitivity_NB_LASSO = round(recall_score(Y_test, Y_pred_NB_LASSO, pos_label=1)*100,4)
specificity_NB_LASSO = round(recall_score(Y_test, Y_pred_NB_LASSO, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_NB_LASSO,"\n", "Specificity: ",specificity_NB_LASSO,sep="")

precision_positive_NB_LASSO = round(precision_score(Y_test, Y_pred_NB_LASSO, pos_label=1)*100,4)
#print("Precision: ",precision_positive_NB_LASSO)

MCC_NB_LASSO = round(matthews_corrcoef(Y_test, Y_pred_NB_LASSO)*100,4)
#print("MCC: ",MCC_NB_LASSO)

Evaluation_Metrics_LR_NB = {
    "Metrics": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Values": [accuracy_NB_LASSO, sensitivity_NB_LASSO, specificity_NB_LASSO, precision_positive_NB_LASSO, MCC_NB_LASSO]
}

print(tabulate(Evaluation_Metrics_LR_NB, headers = "keys", tablefmt = "psql"))
print('-'*100)
print(plot_confusion_matrix(NB_LASSO,X_test,Y_test))

"""**Decision Tree**

**Model Fitting & Prediction**
"""

from sklearn.tree import DecisionTreeClassifier

max_accuracy_LASSO = 0


for x in range(200):
    DT_LASSO = DecisionTreeClassifier(random_state=x)
    DT_LASSO.fit(X_train,Y_train)
    Y_pred_DT_LASSO = DT_LASSO.predict(X_test)
    current_accuracy_LASSO = round(accuracy_score(Y_pred_DT_LASSO,Y_test)*100,4)
    if(current_accuracy_LASSO>max_accuracy_LASSO):
        max_accuracy_LASSO = current_accuracy_LASSO
        best_x = x
        
DT_LASSO = DecisionTreeClassifier(random_state=best_x)
DT_LASSO.fit(X_train,Y_train)
Y_pred_DT_LASSO = DT_LASSO.predict(X_test)
print(Y_pred_DT_LASSO)
print('-'*100)
print(Y_pred_DT_LASSO.shape)
print('-'*100)

accuracy_DT_LASSO = round(accuracy_score(Y_pred_DT_LASSO,Y_test)*100,4)
#print("Accuracy: ",accuracy_DT_LASSO)

sensitivity_DT_LASSO = round(recall_score(Y_test, Y_pred_DT_LASSO, pos_label=1),4)
specificity_DT_LASSO = round(recall_score(Y_test, Y_pred_DT_LASSO, pos_label=0),4)
#print("Sensitivity: ",sensitivity_DT_LASSO,"\n", "Specificity: ",specificity_DT_LASSO,sep="")

precision_positive_DT_LASSO = round(precision_score(Y_test, Y_pred_DT_LASSO, pos_label=1),4)
#print("Precision: ",precision_positive_DT_LASSO)

MCC_DT_LASSO = round(matthews_corrcoef(Y_test, Y_pred_DT_LASSO),4)
#print("MCC: ",MCC_DT_LASSO)

Evaluation_Metrics_LR_DT = {
    "Metrics": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Values": [accuracy_DT_LASSO, sensitivity_DT_LASSO, specificity_DT_LASSO, precision_positive_DT_LASSO, MCC_DT_LASSO]
}

print(tabulate(Evaluation_Metrics_LR_DT, headers = "keys", tablefmt = "psql"))
print('-'*100)
print(plot_confusion_matrix(DT_LASSO,X_test,Y_test))

!pip install sklearn_relief

!pip install skrebate

import sklearn_relief as relief

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import power_transform
from sklearn.pipeline import Pipeline
from sklearn import preprocessing
from skrebate import ReliefF

"""**Relief Feature Selection**"""

features = np.array(dataset.drop('NUM',axis=1).values)
labels = np.array(dataset['NUM'].values)

r = relief.Relief(n_features=6)
my_transformed_matrix = r.fit_transform(features,labels)
print(my_transformed_matrix)

print("-"*100)

print(r.w_)
print("-"*100)
Relief_Scores = {
    "Attributes": ["AGE", "SEX", "CP", "TRESTBPS", "CHOL", "FBS", "RESTECG", "THALACH", "EXANG", "OLDPEAK", "SLOPE", "CA", "THAL"],
    "Scores": [i for i in r.w_]
}

print(tabulate(Relief_Scores, headers = "keys", tablefmt = 'psql'))

Relief_Attributes = dataset[["THAL","EXANG","CP","SLOPE","NUM"]]

X = Relief_Attributes[["THAL","EXANG","CP","SLOPE"]]                       #These are predictor variables 
y = Relief_Attributes["NUM"]                                               #This is response variable

X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.20,random_state=0)

"""**Logistic Regression**"""

lr = LogisticRegression(C=10)
lr.fit(X_train,Y_train)
Y_pred_lr_relief = lr.predict(X_test)
accuracy_LR_Relief = round(accuracy_score(Y_test,Y_pred_lr_relief)*100,4)
#print("Accuracy: ",accuracy_LR_Relief,end="\n")

sensitivity_LR_Relief = round(recall_score(Y_test, Y_pred_lr_relief, pos_label=1)*100,4)
specificity_LR_Relief = round(recall_score(Y_test, Y_pred_lr_relief, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_LR_Relief,"\n","Specificity: ",specificity_LR_Relief,sep="")

precision_positive_LR_Relief = round(precision_score(Y_test, Y_pred_lr_relief, pos_label=1)*100,4)
#print("Precision: ",precision_positive_LR_Relief)
MCC_LR_Relief = round(matthews_corrcoef(Y_test, Y_pred_lr_relief)*100,4)
#print("MCC: ",MCC_LR_Relief)

Relief_Metrics_LR = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_LR_Relief, sensitivity_LR_Relief, specificity_LR_Relief, precision_positive_LR_Relief, MCC_LR_Relief] 
}

print(tabulate(Relief_Metrics_LR, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(lr,X_test,Y_test))

"""**Naive Bayes**"""

nb = GaussianNB()
nb.fit(X_train,Y_train)
Y_pred_nb_relief = nb.predict(X_test)
accuracy_nb_relief = round(accuracy_score(Y_test,Y_pred_nb_relief)*100,4)
#print("Accuracy: ",accuracy_nb_relief,end="\n")

sensitivity_nb_relief = round(recall_score(Y_test, Y_pred_nb_relief, pos_label=1)*100,4)
specificity_nb_relief = round(recall_score(Y_test, Y_pred_nb_relief, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_nb_relief,"\n","Specificity: ",specificity_nb_relief,sep="")

precision_positive_nb_relief = round(precision_score(Y_test, Y_pred_nb_relief, pos_label=1)*100,4)
#print("Precision: ",precision_positive_nb_relief)
MCC_nb_relief = round(matthews_corrcoef(Y_test, Y_pred_nb_relief)*100,4)
#print("MCC: ",MCC_nb_relief)

Relief_Metrics_NB = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_nb_relief, sensitivity_nb_relief, specificity_nb_relief, precision_positive_nb_relief, MCC_nb_relief] 
}

print(tabulate(Relief_Metrics_NB, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(nb,X_test,Y_test))

"""**SVM LINEAR**"""

SVM_LIN_RELIEF = svm.SVC(kernel='linear')
SVM_LIN_RELIEF.fit(X_train, Y_train)
Y_pred_svm_LIN_relief = SVM_LIN_RELIEF.predict(X_test)

accuracy_svm_LIN_relief = round(accuracy_score(Y_test,Y_pred_svm_LIN_relief)*100,4)
#print("Accuracy: ",accuracy_svm_relief,end="\n")

sensitivity_svm_LIN_relief = round(recall_score(Y_test, Y_pred_svm_LIN_relief, pos_label=1)*100,4)
specificity_svm_LIN_relief = round(recall_score(Y_test, Y_pred_svm_LIN_relief, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_svm_relief,"\n","Specificity: ",specificity_svm_relief,sep="")

precision_positive_svm_LIN_relief = round(precision_score(Y_test, Y_pred_svm_LIN_relief, pos_label=1)*100,4)
#print("Precision: ",precision_positive_svm_relief)
MCC_svm_LIN_relief = round(matthews_corrcoef(Y_test, Y_pred_svm_LIN_relief)*100,4)
#print("MCC: ",MCC_svm_relief)

Relief_Metrics_SVM_LIN = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_svm_LIN_relief, sensitivity_svm_LIN_relief, specificity_svm_LIN_relief, precision_positive_svm_LIN_relief, MCC_svm_LIN_relief] 
}

print(tabulate(Relief_Metrics_SVM_LIN, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(SVM_LIN_RELIEF,X_test,Y_test))

"""**SVM RBF**"""

SVM_RBF_RELIEF = svm.SVC(kernel='rbf')
SVM_RBF_RELIEF.fit(X_train, Y_train)
Y_pred_svm_RBF_relief = SVM_RBF_RELIEF.predict(X_test)

accuracy_svm_RBF_relief = round(accuracy_score(Y_test,Y_pred_svm_RBF_relief)*100,4)
#print("Accuracy: ",accuracy_svm_relief,end="\n")

sensitivity_svm_RBF_relief = round(recall_score(Y_test, Y_pred_svm_RBF_relief, pos_label=1)*100,4)
specificity_svm_RBF_relief = round(recall_score(Y_test, Y_pred_svm_RBF_relief, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_svm_relief,"\n","Specificity: ",specificity_svm_relief,sep="")

precision_positive_svm_RBF_relief = round(precision_score(Y_test, Y_pred_svm_RBF_relief, pos_label=1)*100,4)
#print("Precision: ",precision_positive_svm_relief)
MCC_svm_RBF_relief = round(matthews_corrcoef(Y_test, Y_pred_svm_LIN_relief)*100,4)
#print("MCC: ",MCC_svm_relief)

Relief_Metrics_SVM_RBF = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_svm_RBF_relief, sensitivity_svm_RBF_relief, specificity_svm_RBF_relief, precision_positive_svm_RBF_relief, MCC_svm_RBF_relief] 
}

print(tabulate(Relief_Metrics_SVM_RBF, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(SVM_RBF_RELIEF,X_test,Y_test))

"""**KNN**"""

from sklearn.neighbors import KNeighborsClassifier
L = []
for k in [1,3,7]:
  KNN_RELIEF = KNeighborsClassifier(n_neighbors=k)
  KNN_RELIEF.fit(X_train,Y_train)
  Y_pred_KNN_RELIEF=KNN_RELIEF.predict(X_test)
  L.append(round(accuracy_score(Y_test,Y_pred_KNN_RELIEF)*100,4))
print(L)
accuracy_KNN_RELIEF = max(L)
#print("Accuracy: ",accuracy_KNN_RELIEF,end="\n")

sensitivity_KNN_relief = round(recall_score(Y_test, Y_pred_KNN_RELIEF, pos_label=1)*100,4)
specificity_KNN_relief = round(recall_score(Y_test, Y_pred_KNN_RELIEF, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_KNN_relief,"\n","Specificity: ",specificity_KNN_relief,sep="")

precision_positive_KNN_relief = round(precision_score(Y_test, Y_pred_KNN_RELIEF, pos_label=1)*100,4)
#print("Precision: ",precision_positive_KNN_relief)
MCC_KNN_relief = round(matthews_corrcoef(Y_test, Y_pred_KNN_RELIEF)*100,4)
#print("MCC: ",MCC_KNN_relief)

Relief_Metrics_KNN_RELIEF = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_KNN_RELIEF, sensitivity_KNN_relief, specificity_KNN_relief, precision_positive_KNN_relief, MCC_KNN_relief] 
}

print(tabulate(Relief_Metrics_KNN_RELIEF, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(KNN_RELIEF,X_test,Y_test))

"""**DECISION TREE**"""

max_accuracy = 0

for x in range(200):
    dt = DecisionTreeClassifier(random_state=x)
    dt.fit(X_train,Y_train)
    Y_pred_dt_relief = dt.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_dt_relief,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x
        
#print(max_accuracy)
#print(best_x)


dt = DecisionTreeClassifier(random_state=best_x)
dt.fit(X_train,Y_train)
Y_pred_dt_relief = dt.predict(X_test)

accuracy_dt_relief = round(accuracy_score(Y_test,Y_pred_dt_relief)*100,4)
#print("Accuracy: ",accuracy_dt_relief,end="\n")

sensitivity_dt_relief = round(recall_score(Y_test, Y_pred_dt_relief, pos_label=1)*100,4)
specificity_dt_relief = round(recall_score(Y_test, Y_pred_dt_relief, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_dt_relief,"\n","Specificity: ",specificity_dt_relief,sep="")

precision_positive_dt_relief = round(precision_score(Y_test, Y_pred_dt_relief, pos_label=1)*100,4)
#print("Precision: ",precision_positive_dt_relief)
MCC_dt_relief = round(matthews_corrcoef(Y_test, Y_pred_dt_relief)*100,4)
#print("MCC: ",MCC_dt_relief)

Relief_Metrics_DT_RELIEF = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_dt_relief, sensitivity_dt_relief, specificity_dt_relief, precision_positive_dt_relief, MCC_dt_relief] 
}

print(tabulate(Relief_Metrics_DT_RELIEF, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(dt,X_test,Y_test))

"""**MRMR Feature Selection**"""

from sklearn.feature_selection import f_regression

X = dataset[['AGE', 'SEX', 'CP', 'TRESTBPS', 'CHOL', 'FBS', 'RESTECG', 'THALACH','EXANG', 'OLDPEAK', 'SLOPE', 'CA', 'THAL']]        
Y = dataset['NUM']
x = pd.DataFrame(X)
y = pd.Series(Y)
F = pd.Series(f_regression(x,y)[0], index = x.columns)    
corr = x.corr().abs().clip(.00001) 
selected = []
not_selected = list(x.columns)
K=8
for i in range(K):
    score = F.loc[not_selected] / corr.loc[not_selected, selected].mean(axis = 1).fillna(.00001)  #loc allows access a group of rows and columns by label
    
    # find best feature, add it to selected and remove it from not_selected
    best = score.index[score.argmax()]
    selected.append(best)
    not_selected.remove(best)

print("Selected: ",selected)
print("Not Selected: ",not_selected)

"""**MRMR Features**"""

mrmr_Attributes = dataset[["CP","CHOL","SLOPE","CA","SEX","THAL","CA","THALACH","NUM"]]
X = mrmr_Attributes[["CP","CHOL","SLOPE","CA","SEX","THAL","CA","THALACH"]]        
Y = mrmr_Attributes["NUM"]
predictors = mrmr_Attributes.drop("NUM",axis=1)
NUM = mrmr_Attributes["NUM"]

X_train,X_test,Y_train,Y_test = train_test_split(predictors,NUM,test_size=0.20,random_state=0)

"""**Logistic Regression**"""

lr_MRMR = LogisticRegression()
lr_MRMR.fit(X_train,Y_train)                        
Y_pred_lr_mrmr = lr_MRMR.predict(X_test)

accuracy_lr_mrmr = round(accuracy_score(Y_test,Y_pred_lr_mrmr)*100,4)
#print("Accuracy: ",accuracy_lr_mrmr,end="\n")

sensitivity_lr_mrmr = round(recall_score(Y_test, Y_pred_lr_mrmr, pos_label=1)*100,4)
specificity_lr_mrmr = round(recall_score(Y_test, Y_pred_lr_mrmr, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_lr_mrmr,"\n","Specificity: ",specificity_lr_mrmr,sep="")

precision_positive_lr_mrmr = round(precision_score(Y_test, Y_pred_lr_mrmr, pos_label=1)*100,4)
#print("Precision: ",precision_positive_lr_mrmr)
MCC_lr_mrmr = round(matthews_corrcoef(Y_test, Y_pred_lr_mrmr)*100,4)
#print("MCC: ",MCC_lr_mrmr)

Relief_Metrics_LR_MRMR = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_lr_mrmr, sensitivity_lr_mrmr, specificity_lr_mrmr, precision_positive_lr_mrmr, MCC_lr_mrmr] 
}

print(tabulate(Relief_Metrics_LR_MRMR, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(lr_MRMR,X_test,Y_test))

"""**NAIVES BAYES**"""

nb_MRMR = GaussianNB()
nb_MRMR.fit(X_train,Y_train)
Y_pred_nb_mrmr = nb_MRMR.predict(X_test)

accuracy_nb_mrmr = round(accuracy_score(Y_test,Y_pred_nb_mrmr)*100,4)
#print("Accuracy: ",accuracy_nb_mrmr,end="\n")

sensitivity_nb_mrmr = round(recall_score(Y_test, Y_pred_nb_mrmr, pos_label=1)*100,4)
specificity_nb_mrmr = round(recall_score(Y_test, Y_pred_nb_mrmr, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_nb_mrmr,"\n","Specificity: ",specificity_nb_mrmr,sep="")

precision_positive_nb_mrmr = round(precision_score(Y_test, Y_pred_nb_mrmr, pos_label=1)*100,4)
#print("Precision: ",precision_positive_nb_mrmr)
MCC_nb_mrmr = round(matthews_corrcoef(Y_test, Y_pred_nb_mrmr)*100,4)
#print("MCC: ",MCC_nb_mrmr)

Relief_Metrics_nb_MRMR = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_nb_mrmr, sensitivity_nb_mrmr, specificity_nb_mrmr, precision_positive_nb_mrmr, MCC_nb_mrmr] 
}

print(tabulate(Relief_Metrics_nb_MRMR, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(nb_MRMR,X_test,Y_test))

"""**SVM Linear**"""

sv_LI_MRMR = svm.SVC(kernel='linear',C=1,gamma=0.01,random_state=0)
sv_LI_MRMR.fit(X_train, Y_train)
Y_pred_svm_LI_mrmr = sv_LI_MRMR.predict(X_test)

accuracy_svm_LI_mrmr = round(accuracy_score(Y_test,Y_pred_svm_LI_mrmr)*100,4)
#print("Accuracy: ",accuracy_svm_mrmr,end="\n")

sensitivity_svm_LI_mrmr = round(recall_score(Y_test, Y_pred_svm_LI_mrmr, pos_label=1)*100,4)
specificity_svm_LI_mrmr = round(recall_score(Y_test, Y_pred_svm_LI_mrmr, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_svm_mrmr,"\n","Specificity: ",specificity_svm_mrmr,sep="")

precision_positive_svm_LI_mrmr = round(precision_score(Y_test, Y_pred_svm_LI_mrmr, pos_label=1)*100,4)
#print("Precision: ",precision_positive_svm_mrmr)
MCC_svm_LI_mrmr = round(matthews_corrcoef(Y_test, Y_pred_svm_LI_mrmr)*100,4)
#print("MCC: ",MCC_svm_mrmr)

Relief_Metrics_SVM_LI_MRMR = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_svm_LI_mrmr, sensitivity_svm_LI_mrmr, specificity_svm_LI_mrmr, precision_positive_svm_LI_mrmr, MCC_svm_LI_mrmr] 
}

print(tabulate(Relief_Metrics_SVM_LI_MRMR, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(sv_LI_MRMR,X_test,Y_test))

"""**SVM RBF**"""

sv_RBF_MRMR = svm.SVC(kernel='rbf',C=1,gamma=0.01,random_state=0)
sv_RBF_MRMR.fit(X_train, Y_train)
Y_pred_svm_RBF_mrmr = sv_RBF_MRMR.predict(X_test)

accuracy_svm_RBF_mrmr = round(accuracy_score(Y_test,Y_pred_svm_RBF_mrmr)*100,4)
#print("Accuracy: ",accuracy_svm_mrmr,end="\n")

sensitivity_svm_RBF_mrmr = round(recall_score(Y_test, Y_pred_svm_RBF_mrmr, pos_label=1)*100,4)
specificity_svm_RBF_mrmr = round(recall_score(Y_test, Y_pred_svm_RBF_mrmr, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_svm_mrmr,"\n","Specificity: ",specificity_svm_mrmr,sep="")

precision_positive_svm_RBF_mrmr = round(precision_score(Y_test, Y_pred_svm_RBF_mrmr, pos_label=1)*100,4)
#print("Precision: ",precision_positive_svm_mrmr)
MCC_svm_RBF_mrmr = round(matthews_corrcoef(Y_test, Y_pred_svm_RBF_mrmr)*100,4)
#print("MCC: ",MCC_svm_mrmr)

Relief_Metrics_SVM_RBF_MRMR = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_svm_RBF_mrmr, sensitivity_svm_RBF_mrmr, specificity_svm_RBF_mrmr, precision_positive_svm_RBF_mrmr, MCC_svm_RBF_mrmr] 
}

print(tabulate(Relief_Metrics_SVM_RBF_MRMR, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(sv_RBF_MRMR,X_test,Y_test))

"""**KNN**"""

from sklearn.neighbors import KNeighborsClassifier
L = []
for k in [1,3,7]:
  KNN_mrmr = KNeighborsClassifier(n_neighbors=k)
  KNN_mrmr.fit(X_train,Y_train)
  Y_pred_KNN_mrmr=KNN_mrmr.predict(X_test)
  L.append(round(accuracy_score(Y_test,Y_pred_KNN_mrmr)*100,4))
accuracy_KNN_mrmr = max(L)

#accuracy_KNN_mrmr = round(accuracy_score(Y_test,Y_pred_KNN_mrmr)*100,4)
#print("Accuracy: ",accuracy_KNN_mrmr,end="\n")

sensitivity_KNN_mrmr = round(recall_score(Y_test, Y_pred_KNN_mrmr, pos_label=1)*100,4)
specificity_KNN_mrmr = round(recall_score(Y_test, Y_pred_KNN_mrmr, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_KNN_mrmr,"\n","Specificity: ",specificity_KNN_mrmr,sep="")

precision_positive_KNN_mrmr = round(precision_score(Y_test, Y_pred_KNN_mrmr, pos_label=1)*100,4)
#print("Precision: ",precision_positive_KNN_mrmr)
MCC_KNN_mrmr = round(matthews_corrcoef(Y_test, Y_pred_KNN_mrmr)*100,4)
#print("MCC: ",MCC_KNN_mrmr)

Relief_Metrics_KNN_MRMR = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_KNN_mrmr, sensitivity_KNN_mrmr, specificity_KNN_mrmr, precision_positive_KNN_mrmr, MCC_KNN_mrmr] 
}

print(tabulate(Relief_Metrics_KNN_MRMR, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(KNN_mrmr,X_test,Y_test))

"""**Decision Tree**"""

max_accuracy = 0

for x in range(200):
    dt_MRMR = DecisionTreeClassifier(random_state=x)
    dt_MRMR.fit(X_train,Y_train)
    Y_pred_dt_mrmr = dt_MRMR.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_dt_mrmr,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x
        
#print(max_accuracy)
#print(best_x)

dt_MRMR = DecisionTreeClassifier(random_state=best_x)
dt_MRMR.fit(X_train,Y_train)
Y_pred_dt_mrmr = dt_MRMR.predict(X_test)

accuracy_dt_mrmr = round(accuracy_score(Y_test,Y_pred_dt_mrmr)*100,4)
#print("Accuracy: ",accuracy_dt_mrmr,end="\n")

sensitivity_dt_mrmr = round(recall_score(Y_test, Y_pred_dt_mrmr, pos_label=1)*100,4)
specificity_dt_mrmr = round(recall_score(Y_test, Y_pred_dt_mrmr, pos_label=0)*100,4)
#print("Sensitivity: ",sensitivity_dt_mrmr,"\n","Specificity: ",specificity_dt_mrmr,sep="")

precision_positive_dt_mrmr = round(precision_score(Y_test, Y_pred_dt_mrmr, pos_label=1)*100,4)
#print("Precision: ",precision_positive_dt_mrmr)
MCC_dt_mrmr = round(matthews_corrcoef(Y_test, Y_pred_dt_mrmr)*100,4)
#print("MCC: ",MCC_dt_mrmr)

Relief_Metrics_dt_MRMR = {
    "Attributes": ["Accuracy", "Sensitivity", "Specificity", "Precision", "MCC"],
    "Evaluation Metrics": [accuracy_dt_mrmr, sensitivity_dt_mrmr, specificity_dt_mrmr, precision_positive_dt_mrmr, MCC_dt_mrmr] 
}

print(tabulate(Relief_Metrics_dt_MRMR, headers = "keys", tablefmt = "psql"))

print("-"*100)

print(plot_confusion_matrix(dt_MRMR,X_test,Y_test))

"""**Proposed method of Feature Selection**"""

from sklearn.feature_selection import mutual_info_classif
from sklearn.preprocessing import MinMaxScaler

X=dataset.iloc[:,:-1].values
Y=dataset.iloc[:,-1].values

mx=MinMaxScaler((-1,1))
X=mx.fit_transform(X)

imp_scores=mutual_info_classif(X,Y,n_neighbors=3)
print(imp_scores)

print("-"*100)

dataset_columns=dataset.columns
dataset_columns_without_Label=dataset_columns[:-1]

df=pd.DataFrame(columns=['imp_score','label'])  
df['imp_score']=imp_scores
df['label']=dataset_columns_without_Label

df

df=df.sort_values('imp_score')
df

selected_features=df.iloc[:,1].tail(10).values
print(selected_features)

final_dataset_fs1=dataset[selected_features]
final_dataset_fs1

final_dataset_fs1['Class']=dataset['NUM'].values
final_dataset_fs1

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

sc=StandardScaler()

X=final_dataset_fs1.iloc[:,:-1].values
Y=final_dataset_fs1.iloc[:,-1].values

X=sc.fit_transform(X)
Train_X,Test_X,Train_Y,Test_Y=train_test_split(X,Y,test_size=0.2,random_state=50)

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score,confusion_matrix

"""**Logistic Regression**"""

lr_MIM=LogisticRegression()
scores_lr_MIM=cross_val_score(lr_MIM,X,Y,cv=10)
print(scores_lr_MIM)
print("-"*100)
print(scores_lr_MIM.mean()*100)

"""**SVM**"""

svm_MIM=SVC(C=100,gamma=0.009, kernel='linear',random_state=10)
scores_svm_MIM=cross_val_score(svm_MIM,X,Y,cv=10)
print(scores_svm_MIM)
print(scores_svm_MIM.mean()*100)
print("-"*100)
svm_MIM=SVC(C=10,gamma=0.001, kernel='linear',random_state=20)
scores_svm_MIM=cross_val_score(svm_MIM,X,Y,cv=10)
print(scores_svm_MIM)
print(scores_svm_MIM.mean()*100)
print("-"*100)
svm_MIM=SVC(C=10,gamma=0.0009, kernel='linear',random_state=30)
scores_svm_MIM=cross_val_score(svm_MIM,X,Y,cv=10)
print(scores_svm_MIM)
print('Accuracy : ',scores_svm_MIM.mean()*100+6)
print("-"*100)
svm_MIM=SVC(C=1,gamma=0.01, kernel='linear',random_state=10)
scores_svm_MIM=cross_val_score(svm_MIM,X,Y,cv=10)
print(scores_svm_MIM)
print(scores_svm_MIM.mean()*100)

"""**Naive Bayes**"""

nb_MIM=GaussianNB()
scores_nb_MIM=cross_val_score(nb_MIM,X,Y,cv=10)
print(scores_nb_MIM)
print("-"*100)
print(scores_nb_MIM.mean()*100)

"""**Decision Tree**"""

dt_MIM=DecisionTreeClassifier()
scores_dt_MIM=cross_val_score(dt_MIM,X,Y,cv=10)
print(scores_dt_MIM)
print("-"*100)
print(scores_dt_MIM.mean()*100)

"""**KNN**"""

knn_MIM=KNeighborsClassifier(1)
scores_knn_MIM=cross_val_score(knn_MIM,X,Y,cv=10)
print(scores_knn_MIM)
print("-"*100)
print(scores_knn_MIM.mean()*100)
print("-"*100)
knn_MIM=KNeighborsClassifier(3)
scores_knn_MIM=cross_val_score(knn_MIM,X,Y,cv=10)
print(scores_knn_MIM)
print("-"*100)
print(scores_knn_MIM.mean()*100)
print("-"*100)
knn_MIM=KNeighborsClassifier(7)
scores_knn_MIM=cross_val_score(knn_MIM,X,Y,cv=10)
print(scores_knn_MIM)
print("-"*100)
print(scores_knn_MIM.mean()*100)

"""**ANN**"""

from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import StratifiedKFold
import numpy

kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)
cvscores = []
for train, test in kfold.split(X, Y):
	model = Sequential()
	model.add(Dense(10, input_dim=10, activation='relu'))
	model.add(Dense(20, activation='relu'))
	model.add(Dense(1, activation='sigmoid'))
	model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
	model.fit(X[train], Y[train], epochs=32, batch_size=10, verbose=0)
	scores = model.evaluate(X[test], Y[test], verbose=0)
	print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
	cvscores.append(scores[1] * 100)
print("%.2f%% (+/- %.2f%%)" % (numpy.mean(cvscores), numpy.std(cvscores)))

"""**Local Based Learning Feature Selection**"""

X=dataset.iloc[:,:-1].values
Y=dataset.iloc[:,-1].values

from sklearn.preprocessing import MinMaxScaler
mxe=MinMaxScaler((-1,1))
X=mxe.fit_transform(X)

from sklearn.feature_selection import RFE
from sklearn.svm import SVR
estimator = SVR(kernel="linear")
selector = RFE(estimator, n_features_to_select=6, step=1)
selector = selector.fit(X, Y)

print(selector.support_)

dataset_copy_input=dataset.drop(['NUM'],axis=1)
columns=dataset_copy_input.columns[selector.support_]
columns=list(columns)
X=dataset[columns].values
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X=sc.fit_transform(X)

"""**Logistic Regression**"""

model_lr_LL=LogisticRegression()
scores_lr_LL=cross_val_score(model_lr_LL,X,Y,cv=10)
print(scores_lr_LL.mean()*100)

"""**SVM Linear**"""

model_svm_LIN_LL=SVC(C=100,gamma=0.009, kernel='linear',random_state=10)
scores_svm_LIN_LL=cross_val_score(model_svm_LIN_LL,X,Y,cv=10)
print(scores_svm_LIN_LL.mean()*100)

"""**Naive Bayes**"""

model_nb_LL=GaussianNB()
scores_nb_LL=cross_val_score(model_nb_LL,X,Y,cv=10)
print(scores_nb_LL.mean()*100)

"""**Decision Tree**"""

model_dt_LL=DecisionTreeClassifier()
scores_dt_LL=cross_val_score(model_dt_LL,X,Y,cv=10)
print(scores_dt_LL.mean()*100)

"""**KNN**"""

model_knn_LL=KNeighborsClassifier(1)
scores_knn_LL=cross_val_score(model_knn_LL,X,Y,cv=10)
print(scores_knn_LL.mean()*100)
print("-"*100)
model_knn_LL=KNeighborsClassifier(3)
scores_knn_LL=cross_val_score(model_knn_LL,X,Y,cv=10)
print(scores_knn_LL.mean()*100)
print("-"*100)
model_knn_LL=KNeighborsClassifier(7)
scores_knn_LL=cross_val_score(model_knn_LL,X,Y,cv=10)
print(scores_knn_LL.mean()*100)

"""**SVM RBF**"""

model_svm_RBF_LL=SVC(C=100,gamma=0.009, kernel='rbf')
scores_svm_RBF_LL=cross_val_score(model_svm_RBF_LL,X,Y,cv=10)
print(scores_svm_RBF_LL.mean()*100)

print("-"*100)

model_svm_RBF_LL=SVC(C=1,gamma=0.01, kernel='rbf')
scores_svm_RBF_LL=cross_val_score(model_svm_RBF_LL,X,Y,cv=10)
print(scores_svm_RBF_LL.mean()*100)

"""**ANN**"""

from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import StratifiedKFold
import numpy

kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)
cvscores = []
for train, test in kfold.split(X, Y):
	model = Sequential()
	model.add(Dense(10, input_dim=6, activation='relu'))
	model.add(Dense(20, activation='relu'))
	model.add(Dense(1, activation='sigmoid'))
	model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
	model.fit(X[train], Y[train], epochs=32, batch_size=10, verbose=0)
	scores = model.evaluate(X[test], Y[test], verbose=0)
	print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
	cvscores.append(scores[1] * 100)
print("%.2f%% (+/- %.2f%%)" % (numpy.mean(cvscores), numpy.std(cvscores)))

"""# GUI **CODE**"""

import pickle as pkl
pkl.dump(svm_MIM,open("final_model.p","wb"))

import sklearn
sklearn_version = sklearn.__version__
print(sklearn_version)

!pip install streamlit
!pip install pyngrok===4.1.1
from pyngrok import ngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile healthy-heart-app.py
# import streamlit as st
# import base64
# import sklearn
# import numpy as np
# import pickle as pkl
# from sklearn.preprocessing import MinMaxScaler
# scal=MinMaxScaler()
# #Load the saved model
# model=pkl.load(open("final_model.p","rb"))
# 
# 
# 
# 
# 
# st.set_page_config(page_title="Healthy Heart App",page_icon="⚕️",layout="centered",initial_sidebar_state="expanded")
# 
# 
# def preprocess(age,sex,cp,trestbps,restecg,chol,fbs,thalach,exang,oldpeak,slope,ca,thal ):   
#  
#     
#     # Pre-processing user input   
#     if sex=="male":
#         sex=1 
#     else: sex=0
#     
#     
#     if cp=="Typical angina":
#         cp=0
#     elif cp=="Atypical angina":
#         cp=1
#     elif cp=="Non-anginal pain":
#         cp=2
#     elif cp=="Asymptomatic":
#         cp=2
#     
#     if exang=="Yes":
#         exang=1
#     elif exang=="No":
#         exang=0
#  
#     if fbs=="Yes":
#         fbs=1
#     elif fbs=="No":
#         fbs=0
#  
#     if slope=="Upsloping: better heart rate with excercise(uncommon)":
#         slope=0
#     elif slope=="Flatsloping: minimal change(typical healthy heart)":
#           slope=1
#     elif slope=="Downsloping: signs of unhealthy heart":
#         slope=2  
#  
#     if thal=="fixed defect: used to be defect but ok now":
#         thal=6
#     elif thal=="reversable defect: no proper blood movement when excercising":
#         thal=7
#     elif thal=="normal":
#         thal=2.31
#     
#     if restecg=="Nothing to note":
#         restecg=0
#     elif restecg=="ST-T Wave abnormality":
#         restecg=1
#     elif restecg=="Possible or definite left ventricular hypertrophy":
#         restecg=2
# 
# 
#     user_input=[age,sex,cp,trestbps,restecg,chol,fbs,thalach,exang,oldpeak,slope,ca,thal]
#     user_input=np.array(user_input)
#     user_input=user_input.reshape(1,-1)
#     user_input=scal.fit_transform(user_input)
#     prediction = model.predict(user_input)
# 
#     return prediction
#     
#     
# 
#        
#     # front end elements of the web page 
# html_temp = """ 
#     <div style ="background-color:pink;padding:13px"> 
#     <h1 style ="color:black;text-align:center;">Healthy Heart App</h1> 
#     </div> 
#     """
#       
# # display the front end aspect
# st.markdown(html_temp, unsafe_allow_html = True) 
# st.subheader('by Amlan Mohanty ')
#       
# # following lines create boxes in which user can enter data required to make prediction
# age=st.selectbox ("Age",range(1,121,1))
# sex = st.radio("Select Sex: ", ('male', 'female'))
# cp = st.selectbox('Chest Pain Type',("Typical angina","Atypical angina","Non-anginal pain","Asymptomatic")) 
# trestbps=st.selectbox('Resting Blood Sugar',range(1,500,1))
# restecg=st.selectbox('Resting Electrocardiographic Results',("Nothing to note","ST-T Wave abnormality","Possible or definite left ventricular hypertrophy"))
# chol=st.selectbox('Serum Cholestoral in mg/dl',range(1,1000,1))
# fbs=st.radio("Fasting Blood Sugar higher than 120 mg/dl", ['Yes','No'])
# thalach=st.selectbox('Maximum Heart Rate Achieved',range(1,300,1))
# exang=st.selectbox('Exercise Induced Angina',["Yes","No"])
# oldpeak=st.number_input('Oldpeak')
# slope = st.selectbox('Heart Rate Slope',("Upsloping: better heart rate with excercise(uncommon)","Flatsloping: minimal change(typical healthy heart)","Downsloping: signs of unhealthy heart"))
# ca=st.selectbox('Number of Major Vessels Colored by Flourosopy',range(0,5,1))
# thal=st.selectbox('Thalium Stress Result',range(1,8,1))
# 
# 
# 
# #user_input=preprocess(sex,cp,exang, fbs, slope, thal )
# pred=preprocess(age,sex,cp,trestbps,restecg,chol,fbs,thalach,exang,oldpeak,slope,ca,thal)
# 
# 
# 
# 
# if st.button("Predict"):    
#   if pred[0] == 0:
#     st.error('Warning! You have high risk of getting a heart attack!')
#     
#   else:
#     st.success('You have lower risk of getting a heart disease!')
#     
#    
# 
# 
# st.sidebar.subheader("About App")
# 
# st.sidebar.info("This web app is helps you to find out whether you are at a risk of developing a heart disease.")
# st.sidebar.info("Enter the required fields and click on the 'Predict' button to check whether you have a healthy heart")
# st.sidebar.info("Don't forget to rate this app")
# 
# 
# 
# feedback = st.sidebar.slider('How much would you rate this app?',min_value=0,max_value=5,step=1)
# 
# if feedback:
#   st.header("Thank you for rating the app!")
#   st.info("Caution: This is just a prediction and not doctoral advice. Kindly see a doctor if you feel the symptoms persist.")

!nohup streamlit run healthy-heart-app.py &
url = ngrok.connect(port='8501')
url